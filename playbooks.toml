debug = true
timeout_s = 60

[model]
provider = "openai"
name = "gpt-4o"
temperature = 0.2

# Specific model overrides can be added
# [model.execution]
# [model.compilation]

[llm_cache]
enabled = true
type = "disk"
path = ".llm_cache"
